{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da43ac9",
   "metadata": {},
   "source": [
    "## 1 INTROTOCLASSIFICATION/KNN/INTROTOCLASSIFICATION KNN 5 EXERCISE ANSWERS ##\n",
    "#### Exercise ####\n",
    "#### Please refer to module 2 of IntroToClassification - kNN for Tasks 1-8\n",
    "#### Task 1\n",
    "##### Import the required packages.\n",
    "##### Set the working directory to data directory.\n",
    "##### Print the working directory.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee859f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "\n",
    "# Set 'main_dir' to location of the project folder\n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e5ff5",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Read in our dataset called `'heart_failure_clinical_records_dataset.csv'`. Save it as `ex_data`.\n",
    "##### Print the head of `ex_data`.\n",
    "##### Print the type and length of `ex_data`.\n",
    "##### Save the shape of the dataset into two variables `ex_nrow` and `ex_ncol` and print them.\n",
    "##### Subset the dataframe to include only numeric and categorical columns.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = pd.read_csv(\n",
    "    str(data_dir) + \"/\" + \"heart_failure_clinical_records_dataset.csv\"\n",
    ")\n",
    "print(ex_data.head())\n",
    "print(type(ex_data))\n",
    "print(len(ex_data))\n",
    "ex_nrows, ex_ncols = ex_data.shape\n",
    "print(ex_nrows)\n",
    "print(ex_ncols)\n",
    "# Subset data\n",
    "ex_data = ex_data[\n",
    "    [\n",
    "        \"age\",\n",
    "        \"serum_sodium\",\n",
    "        \"time\",\n",
    "        \"platelets\",\n",
    "        \"ejection_fraction\",\n",
    "        \"serum_creatinine\",\n",
    "        \"creatinine_phosphokinase\",\n",
    "        \"anaemia\",\n",
    "        \"high_blood_pressure\",\n",
    "        \"smoking\",\n",
    "        \"sex\",\n",
    "        \"diabetes\",\n",
    "        \"death_event\",\n",
    "        \"id\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bff1dd",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Convert the target to binary if it is not already\n",
    "##### Save the converted data frame as `ex_data` and print its head.\n",
    "##### Print the converted column.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target not binary - calculate the mean and assign the above mean to 1 and below to 0\n",
    "ex_threshold = np.mean(ex_data[\"death_event\"])\n",
    "ex_data[\"death_event\"] = np.where(ex_data[\"death_event\"] > ex_threshold, 0, 1)\n",
    "print(ex_data.head())\n",
    "print(ex_data[\"death_event\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb78e8e",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Check for NAs in `ex_data`\n",
    "##### Fill NAs in `ex_data` with mean.\n",
    "##### Delete columns containing either 50% or more than 50% NaN Values\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NAs.\n",
    "print(ex_data.isnull().sum())\n",
    "ex_percent_missing = ex_data.isnull().sum() * 100 / len(ex_data)\n",
    "print(ex_percent_missing)\n",
    "ex_perc = 50.0\n",
    "ex_min_count = int(((100 - ex_perc) / 100) * ex_data.shape[0] + 1)\n",
    "ex_data = ex_data.dropna(axis=1, thresh=ex_min_count)\n",
    "print(ex_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16691285",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Write a function to impute NA in both numeric and categorical columns\n",
    "##### Use the function to impute NA\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    # Fill numeric columns with mean value\n",
    "    df = df.fillna(df.mean())\n",
    "    # Fill categorical columns with mode value\n",
    "    df = df.fillna(df.mode().iloc[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "ex_data = fillna(ex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66be49",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Convert `death_event` to `bool` dtype so that is a binary class\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6412bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the the two unique classes\n",
    "ex_unique_values = sorted(ex_data[\"death_event\"].unique())\n",
    "ex_data[\"death_event\"] = np.where(\n",
    "    ex_data[\"death_event\"] == ex_unique_values[0], False, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca631ff3",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Split the data into ex_X and ex_y \n",
    "##### Convert categorical data in ex_X to integer values (Hint: use `get_dummies`)\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_columns_to_drop_from_X = [\"death_event\"] + [\"id\"]\n",
    "ex_X = ex_data.drop(ex_columns_to_drop_from_X, axis=1)\n",
    "ex_y = np.array(ex_data[\"death_event\"])\n",
    "ex_X = pd.get_dummies(\n",
    "    ex_X,\n",
    "    columns=[\"anaemia\", \"high_blood_pressure\", \"smoking\", \"sex\", \"diabetes\"],\n",
    "    dtype=float,\n",
    "    drop_first=True,\n",
    ")\n",
    "print(ex_X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48200678",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "##### Set a seed value\n",
    "##### Split data into train and test \n",
    "##### Scale our X and y predictors separately\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "# Split into train and test.\n",
    "ex_X_train, ex_X_test, ex_y_train, ex_y_test = train_test_split(\n",
    "    ex_X, ex_y, test_size=0.3\n",
    ")\n",
    "# Scale X.\n",
    "ex_X_train = scale(ex_X_train)\n",
    "ex_X_test = scale(ex_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcba560",
   "metadata": {},
   "source": [
    "#### Please refer to module 3 of IntroToClassification - kNN for Tasks 9-13\n",
    "#### Task 9\n",
    "##### Set `default = 5`\n",
    "##### Create kNN classifier\n",
    "##### Fit the classifier to the data\n",
    "##### Predict using the classifier and call it predictions\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kNN classifier.\n",
    "ex_default = 5\n",
    "ex_kNN = KNeighborsClassifier(n_neighbors=ex_default)\n",
    "# Fit the classifier to the data.\n",
    "ex_kNN.fit(ex_X_train, ex_y_train)\n",
    "ex_predictions = ex_kNN.predict(ex_X_test)\n",
    "print(ex_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9687e0",
   "metadata": {},
   "source": [
    "#### Task 10\n",
    "##### Print the vector of predicted values versus actual values\n",
    "##### function called `confusion_matrix` from `sklearn.metrics` \n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_actual_v_predicted = np.column_stack((ex_y_test, ex_predictions))\n",
    "print(ex_actual_v_predicted[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a5a1e",
   "metadata": {},
   "source": [
    "#### Task 11\n",
    "##### Print the vector of predicted values versus actual values\n",
    "##### Use function called `confusion_matrix` from `sklearn.metrics` \n",
    "##### Using `accuracy_score` from `sklearn.metrics` calculate the accuracy score\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_actual_v_predicted = np.column_stack((ex_y_test, ex_predictions))\n",
    "print(ex_actual_v_predicted[0:5])\n",
    "print(round(accuracy_score(ex_y_test, ex_predictions), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb3c14",
   "metadata": {},
   "source": [
    "#### Task 12\n",
    "##### Create `ex_cm_kNN` a confusion matrix and print it\n",
    "##### Visualize our confusion matrix\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_cm_kNN = confusion_matrix(ex_y_test, ex_predictions)\n",
    "print(ex_cm_kNN)\n",
    "plt.imshow(ex_cm_kNN, interpolation=\"nearest\", cmap=plt.cm.Wistia)\n",
    "classNames = [\"Negative\", \"Positive\"]\n",
    "plt.title(\"Confusion Matrix - Test Data\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [[\"TN\", \"FP\"], [\"FN\", \"TP\"]]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, str(s[i][j]) + \" = \" + str(ex_cm_kNN[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73070b72",
   "metadata": {},
   "source": [
    "#### Task 13\n",
    "##### Plot the ROC for our model\n",
    "##### Calculate the AUC\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63467087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store FPR, TPR, and threshold as variables.\n",
    "ex_fpr, ex_tpr, ex_threshold = metrics.roc_curve(ex_y_test, ex_predictions)\n",
    "# Store the AUC.\n",
    "ex_roc_auc = metrics.auc(ex_fpr, ex_tpr)\n",
    "# Plot ROC\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(ex_fpr, ex_tpr, \"b\", label=\"AUC = %0.2f\" % ex_roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a1fa9",
   "metadata": {},
   "source": [
    "#### Please refer to module 4 of IntroToClassification - kNN for Task 14\n",
    "#### Task 14\n",
    "##### Create a pipeline of the scaler and Estimator\n",
    "##### Calculate cv scores and print the mean\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline of the scaler and Estimator\n",
    "ex_cv_pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"estimator\", ex_kNN)])\n",
    "ex_cv_scores = cross_val_score(ex_cv_pipeline, ex_X, ex_y, cv=5)\n",
    "print(ex_cv_scores)\n",
    "print(\"cv_scores mean:{}\".format(np.mean(ex_cv_scores)))\n",
    "ex_mean = np.mean(ex_cv_scores)\n",
    "print(\"Optimal cv score is:\", round(ex_mean, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82472b",
   "metadata": {},
   "source": [
    "#### Please refer to module 5 of IntroToClassification - kNN for Tasks 15-19\n",
    "#### Task 15\n",
    "#####  Define the parameter values between 1 and 31 that should be searched as `k_range`\n",
    "##### Create a parameter grid: map the parameter names to the values that should be searched by building a Python dictionary. \n",
    "##### Instantiate the grid using our original model - kNN with k and call it as `grid`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter values that should be searched.\n",
    "ex_k_range = list(range(1, 31))\n",
    "# Create a parameter grid: map the parameter names to the values that should be searched by building a Python dictionary.\n",
    "ex_param_grid = dict(n_neighbors=ex_k_range)\n",
    "print(ex_param_grid)\n",
    "# Instantiate the grid using our original model - kNN with k.\n",
    "ex_grid = GridSearchCV(ex_kNN, ex_param_grid, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61015745",
   "metadata": {},
   "source": [
    "#### Task 16\n",
    "##### Create a pipeline of the scaler and gridsearch as `grid_search_pipeline`\n",
    "##### Fit Gridsearch pipeline\n",
    "##### Print the complete results (list of named tuples).\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline of the scaler and gridsearch\n",
    "ex_grid_search_pipeline = Pipeline(\n",
    "    [(\"transformer\", StandardScaler()), (\"estimator\", ex_grid)]\n",
    ")\n",
    "# Fit Gridsearch pipeline\n",
    "ex_grid_search_pipeline.fit(ex_X, ex_y)\n",
    "# View the complete results (list of named tuples).\n",
    "print(ex_grid.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a227a",
   "metadata": {},
   "source": [
    "#### Task 17\n",
    "##### Create a list of the mean scores only by using a list comprehension to loop through grid.cv_results_ and print it.\n",
    "##### Plot optimal k - plot, by plotting k_range with grid_mean_scores\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa34d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_grid_mean_scores = [result for result in ex_grid.cv_results_[\"mean_test_score\"]]\n",
    "print(ex_grid_mean_scores)\n",
    "# Plot the results.\n",
    "plt.plot(ex_k_range, ex_grid_mean_scores)\n",
    "plt.xlabel(\"Value of K for kNN\")\n",
    "plt.ylabel(\"Cross-Validated Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717b5c2",
   "metadata": {},
   "source": [
    "#### Task 18\n",
    "##### Print the vector of predicted values versus actual values\n",
    "##### function called `confusion_matrix` from `sklearn.metrics` \n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_actual_v_predicted = np.column_stack((ex_y_test, ex_predictions))\n",
    "print(ex_actual_v_predicted[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b9652",
   "metadata": {},
   "source": [
    "#### Task 19\n",
    "##### Print the single best score achieved across all params (k).\n",
    "##### Print the dictionary containing the parameters (k) used to generate that score.\n",
    "##### Actual model object fit with those best parameters (Hint: use best_estimator_)\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single best score achieved across all params (k).\n",
    "print(ex_grid.best_score_)\n",
    "# Dictionary containing the parameters (k) used to generate that score.\n",
    "print(ex_grid.best_params_)\n",
    "# Actual model object fit with those best parameters.\n",
    "# Shows default parameters that we did not specify.\n",
    "print(ex_grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
