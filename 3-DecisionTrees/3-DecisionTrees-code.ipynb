{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61961170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 3 DECISIONTREES/DECISIONTREES/DECISIONTREES DECISIONTREES 2 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3254fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 3: Loading packages  ####\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "plot_dir = str(main_dir) + \"/plots\"\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "print(plot_dir)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1aa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Load the dataset  ####\n",
    "\n",
    "df = pd.read_csv(str(data_dir)+\"/\"+ 'healthcare-dataset-stroke-data.csv')\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 5: Subset data  ####\n",
    "\n",
    "df = df[['age', 'avg_glucose_level', 'heart_disease', 'ever_married', 'hypertension', 'Residence_type', 'gender', 'smoking_status', 'work_type', 'stroke', 'id']]\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128944b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Data prep: check for NAs  ####\n",
    "\n",
    " # Check for NAs. \n",
    "print(df.isnull().sum())\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "print(percent_missing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d89101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: Data prep: check for NAs  ####\n",
    "\n",
    "# Delete columns containing either 50% or more than 50% NaN Values\n",
    "perc = 50.0\n",
    "min_count =  int(((100-perc)/100)*df.shape[0] + 1)\n",
    "df = df.dropna(axis=1, \n",
    "               thresh=min_count)\n",
    "print(df.shape)\n",
    "# Function to impute NA in both numeric and categorical columns\n",
    "def fillna(df):\n",
    "    # Fill numeric columns with mean value\n",
    "    df = df.fillna(df.mean())    \n",
    "    # Fill categorical columns with mode value\n",
    "    df = df.fillna(df.mode().iloc[0])\n",
    "    return df\n",
    "  \n",
    "df = fillna(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f251ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 8: Data prep: target  ####\n",
    "\n",
    "print(df['stroke'].dtypes)\n",
    "# Identify the the two unique classes\n",
    "threshold = df['stroke'].mean()\n",
    "df['stroke'] = np.where(df['stroke'] > threshold, 1,0)\n",
    "unique_values = sorted(df['stroke'].unique())\n",
    "df['stroke'] = np.where(df['stroke'] == unique_values[0],  False,True)\n",
    "# Check class again.\n",
    "print(df['stroke'].dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Summarize the data  ####\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faedf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Decision Tree: splitting the data  ####\n",
    "\n",
    "# Split the data into X and y \n",
    "columns_to_drop_from_X = ['stroke'] + ['id']\n",
    "X = df.drop(columns_to_drop_from_X, axis = 1)\n",
    "y = np.array(df['stroke'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Data prep: numeric variables  ####\n",
    "\n",
    "X = pd.get_dummies(X, columns = ['heart_disease', 'ever_married', 'hypertension', 'Residence_type', 'gender', 'smoking_status', 'work_type'], dtype=float, drop_first=True)\n",
    "print(X.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33930d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 15: Decision Tree: running the algorithm  ####\n",
    "\n",
    "# Implement the decision tree on X.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf_fit = clf.fit(X, y)\n",
    "\n",
    "# Look at our generated model:\n",
    "print(clf_fit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54823f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Visualize: plot_tree  ####\n",
    "\n",
    "# Set figure size\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "# Visualize `clf_fit_small`\n",
    "tree.plot_tree(clf_fit, \n",
    "              feature_names= X.columns,  \n",
    "              filled=True)\n",
    "# Save figure\n",
    "plt.savefig(str(plot_dir)+'/tree.png',format='png',bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 19: Split into train and test sets  ####\n",
    "\n",
    "# Split into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Fit Decision Tree and predict  ####\n",
    "\n",
    "# Implement the decision tree on X_train.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict = clf_fit.predict(X_test)\n",
    "y_predict[:20]\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 3 DECISIONTREES/DECISIONTREES/DECISIONTREES DECISIONTREES 3 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 5: Evaluate the model (cont'd)  ####\n",
    "\n",
    "# Confusion matrix for first model.\n",
    "cm_tree = confusion_matrix(y_test,y_predict)\n",
    "# Accuracy score.\n",
    "acc_score = accuracy_score(y_test, y_predict)\n",
    "print(acc_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Plot confusion matrix  ####\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_tree, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j]) + \" = \" + str(cm_tree[i][j]))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: Plot ROC and calculate AUC  ####\n",
    "\n",
    "\n",
    "# Calculate metrics for ROC (fpr, tpr) and calculate AUC.\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_predict)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC.\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Decision Tree: build  ####\n",
    "\n",
    "# Set up logistic regression model.\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print(clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Decision Tree: fit  ####\n",
    "\n",
    "# Fit the model.\n",
    "clf_fit = clf.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 11: Decision Tree: predict  ####\n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict = clf_fit.predict(X_test)\n",
    "print(y_predict[:20])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56051182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Decision Tree: accuracy score  ####\n",
    "\n",
    "# Compute test model accuracy score.\n",
    "tree_accuracy_score = metrics.accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy on test data: \", tree_accuracy_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Decision Tree: train accuracy  ####\n",
    "\n",
    "# Compute accuracy using training data.\n",
    "acc_train_tree = clf_fit.score(X_train,\n",
    "                                 y_train)\n",
    "print (\"Train Accuracy:\", acc_train_tree)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7df835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 14: Decision Tree: accuracy  ####\n",
    "\n",
    "# Save this model to use later if needed\n",
    "model_final_tree = {'metrics' : \"accuracy\" , \n",
    "                                  'values' : round(tree_accuracy_score,4),\n",
    "                                  'model':'tree_all_variables' }\n",
    "print(model_final_tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65646c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Cross-validation scores  ####\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "cv_scores = cross_val_score(clf, X, y, cv = 10)\n",
    "# Print each cv score (accuracy) and average them.\n",
    "print(cv_scores)\n",
    "print(\"cv_scores mean:{}\".format(np.mean(cv_scores)))\n",
    "mean = np.mean(cv_scores)\n",
    "print(\"Optimal cv score is:\", round(mean, 4))\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36379b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## 3 DECISIONTREES/DECISIONTREES/DECISIONTREES DECISIONTREES 4 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 4: Define an optimal number function  ####\n",
    "\n",
    "# Define function that will determine the optimal number for each parameter.\n",
    "def optimal_parameter(values,test_results):\n",
    "    best_test_value = max(test_results)\n",
    "    best_test_index = test_results.index(best_test_value)\n",
    "    best_value = values[best_test_index]\n",
    "    return(best_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 6: Optimize: max depth  ####\n",
    "\n",
    "# Max depth:\n",
    "max_depths = np.linspace(1, 32, 32, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth = max_depth)\n",
    "   dt.fit(X_train, y_train)\n",
    "   \n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   \n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "# Store optimal max_depth.\n",
    "optimal_max_depth = optimal_parameter(max_depths,test_results)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 7: Plot: max depth  ####\n",
    "\n",
    "# Plot max depth over 1 - 32. \n",
    "line1, = plt.plot(max_depths, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints = 2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 9: Optimize: min samples split  ####\n",
    "\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "   dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "# Store optimal max_depth.\n",
    "optimal_min_samples_split = optimal_parameter(min_samples_splits,test_results) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40829f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 10: Plot: min samples split  ####\n",
    "\n",
    "# Plot min_sample split.\n",
    "line1, = plt.plot(min_samples_splits, train_results, 'b', label = \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label = \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 12: Optimize: min samples leaf  ####\n",
    "\n",
    "# Min_samples_leaf:\n",
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint = True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "\n",
    "optimal_min_samples_leafs = optimal_parameter(min_samples_leafs,test_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 13: Plot: min samples leaf  ####\n",
    "\n",
    "# Plot min_sample split.\n",
    "line1, = plt.plot(min_samples_leafs, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('min samples leafs')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f12f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 15: Optimize: max features  ####\n",
    "\n",
    "# Max_features:\n",
    "max_features = list(range(1,X.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_feature in max_features:\n",
    "   dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   acc_train = accuracy_score(y_train, train_pred)\n",
    "   # Add accuracy score to previous train results\n",
    "   train_results.append(acc_train)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   acc_test = accuracy_score(y_test, y_pred)\n",
    "   \n",
    "   # Add accuracy score to previous test results\n",
    "   test_results.append(acc_test)\n",
    "\n",
    "optimal_max_features = optimal_parameter(max_features,test_results) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Plot: max features  ####\n",
    "\n",
    "# Plot min_sample split.\n",
    "line1, = plt.plot(max_features, train_results, 'b', label= \"Train accuracy\")\n",
    "line2, = plt.plot(max_features, test_results, 'r', label= \"Test accuracy\")\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('max features')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d42d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 18: Optimized model  ####\n",
    "\n",
    "print(\"The optimal max depth is:\", optimal_max_depth)\n",
    "print(\"The optimal min samples split is:\", optimal_min_samples_split)\n",
    "print(\"The optimal min samples leaf is:\", optimal_min_samples_leafs)\n",
    "print(\"The optimal max features is:\", optimal_max_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 19: Build optimized model  ####\n",
    "\n",
    "# Set the seed.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Implement the Decision Tree on X_train.\n",
    "clf_optimized = tree.DecisionTreeClassifier(max_depth = optimal_max_depth,\n",
    "                                            min_samples_split = optimal_min_samples_split,\n",
    "                                            min_samples_leaf = optimal_min_samples_leafs,\n",
    "                                            max_features = optimal_max_features)\n",
    "                                            \n",
    "# We can now see our optimized features where before they were just default:\n",
    "print(clf_optimized)\n",
    "\n",
    "clf_optimized_fit = clf_optimized.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Predict with optimized model  ####\n",
    "\n",
    "# Predict on X_test.\n",
    "y_predict_optimized = clf_optimized_fit.predict(X_test)\n",
    "\n",
    "# Get the accuracy score.\n",
    "acc_score_tree_optimized = accuracy_score(y_test, y_predict_optimized)\n",
    "\n",
    "print(acc_score_tree_optimized)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 21: Train accuracy  ####\n",
    "\n",
    "# Compute accuracy using training data.\n",
    "acc_train_tree_optimized = clf_optimized_fit.score(X_train,\n",
    "                                         y_train)\n",
    "                                         \n",
    "print (\"Train Accuracy:\", acc_train_tree_optimized)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 23: Predict and save results  ####\n",
    "\n",
    "# Add the optimized model to our dataframe.\n",
    "model_final_tree = {'metrics' : \"accuracy\" , \n",
    "             'values' : round(acc_score_tree_optimized,4),\n",
    "             'model':'tree_all_variables_optimized' }\n",
    "print(model_final_tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a881bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 25: Exercise  ####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####  CONGRATULATIONS ON COMPLETING THIS MODULE!   ####\n",
    "#######################################################\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
